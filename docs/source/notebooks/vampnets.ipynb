{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAMPNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sktime\n",
    "import sktime.decomposition.vampnet as vnet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_num_threads(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = sktime.data.ellipsoids()\n",
    "data = data_source.observations(100000, n_dim=5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset in two dimensions: Jump process between two metastable states where each of the states is observed in form of an ellipsoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as ml\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "x = np.linspace(-8,8,500)\n",
    "y = np.linspace(-6,10,500)\n",
    "X, Y = np.meshgrid(x,y)\n",
    "pos = np.empty(X.shape + (2,))\n",
    "pos[:, :, 0] = X\n",
    "pos[:, :, 1] = Y\n",
    "rv1 = multivariate_normal(data_source.state_0_mean, data_source.covariance_matrix)\n",
    "rv2 = multivariate_normal(data_source.state_1_mean, data_source.covariance_matrix)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "\n",
    "ax.contourf(X, Y, (rv1.pdf(pos) + rv2.pdf(pos)).reshape(len(x), len(y)))\n",
    "ax.autoscale(False)\n",
    "ax.scatter(*(data_source.observations(100).T), color='cyan', marker='x',label='samples')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and validation set, move the validation set into a torch tensor and onto the appropriate device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=.3, shuffle=False)\n",
    "val_data_tensor = torch.tensor(val_data, requires_grad=False, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network lobe. Optionally one can use two lobes, one for the instantaneous and one for the time-shifted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lobe(nn.Module):\n",
    "    \n",
    "    def __init__(self, fan_in, fan_out, n_hidden=5):\n",
    "        super().__init__()\n",
    "        layers = [nn.BatchNorm1d(fan_in), nn.Linear(fan_in, 20), nn.ELU()] \\\n",
    "                 + [nn.Linear(20, 20), nn.ELU()]*(n_hidden -1) \\\n",
    "                 + [nn.Linear(20, fan_out), nn.Softmax(1)]\n",
    "        self._seq = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return self._seq(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an instance of the lobe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lobe = Lobe(fan_in=data.shape[1], fan_out=2, n_hidden=3).to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer to train the brain as well as some hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 1\n",
    "n_epochs = 50\n",
    "batch_size = 1024\n",
    "score_method = \"VAMP1\"\n",
    "\n",
    "opt = torch.optim.Adam(lobe.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_train_x = []\n",
    "scores_train = []\n",
    "scores_val_x = []\n",
    "scores_val = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the lobe using our preferred score method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    \n",
    "    ####### TRAINING #######\n",
    "    lobe.train()\n",
    "    for batch_0, batch_t in sktime.data.timeshifted_split(train_data, chunksize=batch_size, \n",
    "                                                          lagtime=tau, shuffle=True):\n",
    "        batch_0 = torch.from_numpy(batch_0).to(device=device)\n",
    "        batch_t = torch.from_numpy(batch_t).to(device=device)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        x_0 = lobe(batch_0)\n",
    "        x_t = lobe(batch_t)\n",
    "        loss = vnet.loss(x_0, x_t, method=score_method)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        scores_train_x.append(step)\n",
    "        scores_train.append(loss.detach().cpu().numpy())\n",
    "        step += 1\n",
    "    \n",
    "    ####### VALIDATION #######\n",
    "    lobe.eval()\n",
    "    with torch.no_grad():\n",
    "        val = lobe(val_data_tensor)\n",
    "        val_score = sktime.decomposition.VAMP(lagtime=tau, epsilon=1e-12)\\\n",
    "                        .fit(val.cpu().numpy()).fetch_model().score(score_method=score_method)\n",
    "\n",
    "        scores_val_x.append(step)\n",
    "        scores_val.append(val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores tell us that we did not overfit and managed to improve the VAMP score a bit by the learned featurization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(scores_train_x, -np.array(scores_train), label='train')\n",
    "plt.semilogy(scores_val_x, scores_val, label='val')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can obtain a koopman model from our learnt featurization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "koopman_model = vnet.VAMPNet(lagtime=tau, lobe=lobe).fit(data).fetch_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can be used to further transform the data, compute timescales and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = koopman_model.transform(data)\n",
    "dtraj = sktime.clustering.KmeansClustering(2).fit(projection).transform(projection)\n",
    "msm = sktime.markov.msm.MaximumLikelihoodMSM().fit(dtraj, lagtime=1).fetch_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"estimated transition matrix\", msm.transition_matrix)\n",
    "print(\"reference transition matrix\", data_source.msm.transition_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The population of states from the data should be roughly 50/50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_states_pie_chart():\n",
    "    coors = []\n",
    "    n_states = np.max(dtraj)+1\n",
    "\n",
    "    for i in range(n_states):\n",
    "        coors.append(np.sum(dtraj==i))\n",
    "    total = len(dtraj)\n",
    "    \n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.pie(np.array(coors), autopct='%1.2f%%', startangle=90)\n",
    "    ax1.axis('equal')\n",
    "    print('States population: '+str(np.array(coors)/total*100)+'%')\n",
    "    plt.show()\n",
    "\n",
    "print_states_pie_chart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The projection can be visualized (here just the first 550 steps) also comparing to the vanilla estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = sktime.decomposition.VAMP(lagtime=1, dim=1).fit(data).fetch_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(projection[:550][:, 0], label='VAMPNet estimator');\n",
    "plt.plot(linear_model.transform(data)[:550][:, 0], label='VAMP estimator', linestyle='dotted')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated timescales are larger then the ones we would have gotten by just using the plain data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('VAMPNet timescale:', koopman_model.timescales()[0])\n",
    "print('VAMP timescale:', linear_model.timescales()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('VAMPNet score:', koopman_model.score())\n",
    "print('VAMP score:', linear_model.score())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "3d47a89e44fa4e1cb0cdf57eb4fcc7a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e8d59b64e45e46e586551704bd8c5df0",
       "max": 50,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_475e23a726c04861bfd9c05da51ae8d9",
       "value": 50
      }
     },
     "475e23a726c04861bfd9c05da51ae8d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "a9cd6a6d14784508978bbd6f802473c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce10968ffb1842fe8ad5a23f91c4672e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d429d0391d8c4f9fa1cd9efd420adc04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e3abadc31f6343c286d61e9443186073": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ce10968ffb1842fe8ad5a23f91c4672e",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_d429d0391d8c4f9fa1cd9efd420adc04",
       "value": " 50/50 [00:28&lt;00:00,  1.78it/s]"
      }
     },
     "e8d59b64e45e46e586551704bd8c5df0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f438f1c90e2a4df0840250aa274e08f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3d47a89e44fa4e1cb0cdf57eb4fcc7a8",
        "IPY_MODEL_e3abadc31f6343c286d61e9443186073"
       ],
       "layout": "IPY_MODEL_a9cd6a6d14784508978bbd6f802473c2"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
